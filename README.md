# Kaggle-ML-Regression

## Abstract
Machine Learning implementation on various competitions primarily on regression model

### 1. Titanic: Machine Learning from Disaster
####   Practice Skills
 - Binary classification
 - Python and R basics
  
### 2. Bike Sharing Demand
####   Practice Skills
 - Linear Regression
 - Ridge, Lasso Models
 - Random Forest
 - Gradient Boosting
  
### 3. House Prices: Advanced Regression Techniques
####   Practice Skills
 - Linear Regression
 - Ridge, Lasso, Elastic Net Models
 - Gradient Boosting, XGBoost, LGBM
 - Ensemble Learning
 - Ensemble of Metamodels

## Presentation
<img src="presentation.gif" alt="result" width="500">

## Result
**Top 13%** (334 out of 4307 teams) on the leaderboard

## References
**Titatic**
1.  Predicting Titanic Survivors by **Minsuk Heo**
<br>https://www.youtube.com/watch?v=aqp_9HV58Ls

**Bike**
1. Predicting Bike Sharing Demand by **todaycodes**
<br>https://www.youtube.com/watch?v=Q_MbN-vu_2w 

**House**
1. Comprehensive data exploration with Python by **Pedro Marcelino** 
<br>https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python
2. Stacked Regressions : Top 4% on LeaderBoard by **Serigne**
<br>https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard
